{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9ab87a",
   "metadata": {},
   "source": [
    "# Retail Data Warehouse Build\n",
    "\n",
    "Build star schema (DimDate, DimProduct, DimCustomer, DimGeography, FactSales) from `raw_data/Online Retail.xlsx` and run example queries.\n",
    "\n",
    "If dependencies are missing install:\n",
    "```\n",
    "pip install pandas openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4580e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports, root + DB connection (change DB_PATH to persist)\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Resolve project root as parent of this notebook file\n",
    "NOTEBOOK_PATH = Path.cwd()\n",
    "# If running from a different CWD, attempt to locate raw_data by walking up\n",
    "potential = [NOTEBOOK_PATH] + list(NOTEBOOK_PATH.parents)\n",
    "DATA_FILE = 'Online Retail.xlsx'\n",
    "DATA_PATH = None\n",
    "for base in potential:\n",
    "    candidate = base / 'raw_data' / DATA_FILE\n",
    "    if candidate.exists():\n",
    "        DATA_PATH = candidate\n",
    "        break\n",
    "if DATA_PATH is None:\n",
    "    print('Data file not found. Checked:')\n",
    "    for base in potential:\n",
    "        print(' -', (base / 'raw_data' / DATA_FILE))\n",
    "else:\n",
    "    print('Using data file:', DATA_PATH)\n",
    "\n",
    "DB_PATH = ':memory:'  # change to 'retail_dw.sqlite' to persist\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "conn.execute('PRAGMA foreign_keys = ON;')\n",
    "print('SQLite version:', conn.execute('select sqlite_version();').fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f5dff",
   "metadata": {},
   "source": [
    "## Load Source Data\n",
    "Expected columns: InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel source into DataFrame; show sample & row count\n",
    "# Expected columns: InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country\n",
    "from pathlib import Path\n",
    "if DATA_PATH is None or not Path(DATA_PATH).exists():\n",
    "    raise FileNotFoundError('Cannot locate data file. Ensure script run from project root or adjust path.')\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "print(df.head())\n",
    "print('Rows:', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c61d14",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "- Drop missing InvoiceNo / StockCode\n",
    "- Fill missing description with 'Unknown'\n",
    "- Normalize string casing\n",
    "- Mark returns (negative quantity)\n",
    "- Anonymous customer for NULL CustomerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean + derive metrics\n",
    "# - Remove blank keys, normalize text\n",
    "# - Mark returns (negative quantity)\n",
    "# - Derive sales_amount metrics and keep nullable CustomerID\n",
    "\n",
    "df = df.dropna(subset=['InvoiceNo','StockCode'])\n",
    "df['Description'] = df['Description'].fillna('Unknown').str.strip()\n",
    "df['StockCode'] = df['StockCode'].astype(str).str.strip()\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype(str).str.strip()\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Country'] = df['Country'].astype(str).str.strip()\n",
    "df['CustomerID'] = df['CustomerID'].astype('Int64')\n",
    "\n",
    "df['is_return'] = (df['Quantity'] < 0).astype(int)\n",
    "df['sales_amount'] = df['Quantity'] * df['UnitPrice']\n",
    "df['sales_amount_abs'] = df['sales_amount'].abs()\n",
    "print('After cleaning rows:', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d327a",
   "metadata": {},
   "source": [
    "## DimDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df['InvoiceDate'].min().normalize()\n",
    "max_date = df['InvoiceDate'].max().normalize()\n",
    "date_range = pd.date_range(min_date, max_date, freq='D')\n",
    "dim_date = pd.DataFrame({'full_date': date_range})\n",
    "dim_date['date_key'] = dim_date['full_date'].dt.strftime('%Y%m%d').astype(int)\n",
    "dim_date['day'] = dim_date['full_date'].dt.day\n",
    "dim_date['month'] = dim_date['full_date'].dt.month\n",
    "dim_date['month_name'] = dim_date['full_date'].dt.strftime('%B')\n",
    "dim_date['quarter'] = dim_date['full_date'].dt.quarter\n",
    "dim_date['year'] = dim_date['full_date'].dt.year\n",
    "dim_date['week_of_year'] = dim_date['full_date'].dt.isocalendar().week.astype(int)\n",
    "# pandas uses 0=Monday via dayofweek; convert to 1-7 ISO style\n",
    "dim_date['day_of_week'] = dim_date['full_date'].dt.dayofweek + 1\n",
    "dim_date['is_weekend'] = dim_date['day_of_week'].isin([6,7]).astype(int)\n",
    "dim_date = dim_date[['date_key','full_date','day','month','month_name','quarter','year','week_of_year','day_of_week','is_weekend']]\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee3f9e",
   "metadata": {},
   "source": [
    "## DimGeography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DimDate spanning min..max invoice dates\n",
    "min_date = df['InvoiceDate'].min().normalize()\n",
    "max_date = df['InvoiceDate'].max().normalize()\n",
    "date_range = pd.date_range(min_date, max_date, freq='D')\n",
    "dim_date = pd.DataFrame({'full_date': date_range})\n",
    "dim_date['date_key'] = dim_date['full_date'].dt.strftime('%Y%m%d').astype(int)\n",
    "dim_date['day'] = dim_date['full_date'].dt.day\n",
    "dim_date['month'] = dim_date['full_date'].dt.month\n",
    "dim_date['month_name'] = dim_date['full_date'].dt.strftime('%B')\n",
    "dim_date['quarter'] = dim_date['full_date'].dt.quarter\n",
    "dim_date['year'] = dim_date['full_date'].dt.year\n",
    "dim_date['week_of_year'] = dim_date['full_date'].dt.isocalendar().week.astype(int)\n",
    "# Convert to ISO 1-7 (Mon-Sun)\n",
    "dim_date['day_of_week'] = dim_date['full_date'].dt.dayofweek + 1\n",
    "dim_date['is_weekend'] = dim_date['day_of_week'].isin([6,7]).astype(int)\n",
    "dim_date = dim_date[['date_key','full_date','day','month','month_name','quarter','year','week_of_year','day_of_week','is_weekend']]\n",
    "dim_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5da48",
   "metadata": {},
   "source": [
    "## DimCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DimGeography (country -> surrogate key); region placeholder\n",
    "countries = sorted(df['Country'].dropna().unique())\n",
    "dim_geog = pd.DataFrame({'country': countries})\n",
    "dim_geog['region'] = None  # can enrich later\n",
    "dim_geog['geography_key'] = range(1, len(dim_geog)+1)\n",
    "dim_geog = dim_geog[['geography_key','country','region']]\n",
    "dim_geog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33d70b",
   "metadata": {},
   "source": [
    "## DimProduct (simple category inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663169ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DimCustomer with surrogate keys + anonymous row (key 0)\n",
    "customer_ids = df['CustomerID'].dropna().unique()\n",
    "dim_customer = pd.DataFrame({'customer_id': sorted(customer_ids)})\n",
    "dim_customer['customer_key'] = range(1, len(dim_customer)+1)\n",
    "dim_customer['customer_name'] = None\n",
    "dim_customer['gender'] = None\n",
    "dim_customer['birth_year'] = None\n",
    "dim_customer['segment'] = 'Retail'\n",
    "# map predominant country per customer (mode)\n",
    "cust_country = (df.dropna(subset=['CustomerID'])\n",
    "                  .groupby('CustomerID')['Country']\n",
    "                  .agg(lambda x: x.value_counts().idxmax()))\n",
    "dim_customer = dim_customer.merge(cust_country.rename('Country'), left_on='customer_id', right_index=True, how='left')\n",
    "dim_customer = dim_customer.merge(dim_geog[['geography_key','country']], left_on='Country', right_on='country', how='left')\n",
    "dim_customer['customer_since_date_key'] = None\n",
    "dim_customer = dim_customer[['customer_key','customer_id','customer_name','gender','birth_year','geography_key','customer_since_date_key','segment']]\n",
    "# anonymous fallback\n",
    "anon = pd.DataFrame([{'customer_key':0,'customer_id':None,'customer_name':'Anonymous','gender':None,'birth_year':None,'geography_key':dim_geog.sample(1)['geography_key'].iloc[0],'customer_since_date_key':None,'segment':'Retail'}])\n",
    "dim_customer = pd.concat([anon, dim_customer], ignore_index=True)\n",
    "dim_customer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350658a",
   "metadata": {},
   "source": [
    "## Create Tables (DDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f26590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DimProduct; simple keyword-based category inference placeholder\n",
    "\n",
    "def infer_category(desc: str) -> str:\n",
    "    if not isinstance(desc, str): return 'Unknown'\n",
    "    d = desc.lower()\n",
    "    if 'mug' in d: return 'Mugs'\n",
    "    if 'bag' in d: return 'Bags'\n",
    "    if 'card' in d: return 'Cards'\n",
    "    if 'candle' in d: return 'Candles'\n",
    "    return 'Other'\n",
    "\n",
    "products = df[['StockCode','Description']].drop_duplicates().copy()\n",
    "products['category'] = products['Description'].apply(infer_category)\n",
    "products['subcategory'] = None\n",
    "products['unit_of_measure'] = 'each'\n",
    "products['first_sale_date_key'] = None\n",
    "products['is_active'] = 1\n",
    "products['product_key'] = range(1, len(products)+1)\n",
    "\n",
    "dim_product = products[['product_key','StockCode','Description','category','subcategory','unit_of_measure','first_sale_date_key','is_active']]\n",
    "dim_product.rename(columns={'StockCode':'stock_code','Description':'description'}, inplace=True)\n",
    "dim_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc5321",
   "metadata": {},
   "source": [
    "## Load Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd91368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables (simplified DDL version; constraints trimmed for clarity)\n",
    "conn.executescript(\n",
    "'''\n",
    "DROP TABLE IF EXISTS FactSales;\n",
    "DROP TABLE IF EXISTS DimProduct;\n",
    "DROP TABLE IF EXISTS DimCustomer;\n",
    "DROP TABLE IF EXISTS DimGeography;\n",
    "DROP TABLE IF EXISTS DimDate;\n",
    "CREATE TABLE DimDate (date_key INTEGER PRIMARY KEY, full_date DATE, day INTEGER, month INTEGER, month_name TEXT, quarter INTEGER, year INTEGER, week_of_year INTEGER, day_of_week INTEGER, is_weekend INTEGER);\n",
    "CREATE TABLE DimGeography (geography_key INTEGER PRIMARY KEY, country TEXT, region TEXT);\n",
    "CREATE TABLE DimProduct (product_key INTEGER PRIMARY KEY, stock_code TEXT, description TEXT, category TEXT, subcategory TEXT, unit_of_measure TEXT, first_sale_date_key INTEGER, is_active INTEGER);\n",
    "CREATE TABLE DimCustomer (customer_key INTEGER PRIMARY KEY, customer_id INTEGER, customer_name TEXT, gender TEXT, birth_year INTEGER, geography_key INTEGER, customer_since_date_key INTEGER, segment TEXT);\n",
    "CREATE TABLE FactSales (fact_sales_key INTEGER PRIMARY KEY, date_key INTEGER, product_key INTEGER, customer_key INTEGER, geography_key INTEGER, invoice_no TEXT, quantity INTEGER, unit_price NUMERIC, sales_amount NUMERIC, sales_amount_abs NUMERIC, is_return INTEGER, load_timestamp DATETIME DEFAULT (datetime('now')));\n",
    "'''\n",
    ")\n",
    "print('Tables created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049f634",
   "metadata": {},
   "source": [
    "## Prepare Fact Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dimension DataFrames into SQLite\n",
    "for name, frame in [('DimDate',dim_date), ('DimGeography',dim_geog), ('DimProduct',dim_product), ('DimCustomer',dim_customer)]:\n",
    "    frame.to_sql(name, conn, if_exists='append', index=False)\n",
    "    print(name, conn.execute(f'SELECT COUNT(*) FROM {name}').fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a79af",
   "metadata": {},
   "source": [
    "## Load Fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare fact rows: map natural keys to surrogate keys\n",
    "product_map = dim_product.set_index('stock_code')['product_key'].to_dict()\n",
    "customer_map = dim_customer.set_index('customer_id')['customer_key'].to_dict()\n",
    "geog_map = dim_geog.set_index('country')['geography_key'].to_dict()\n",
    "date_map = dim_date.set_index('full_date')['date_key'].to_dict()\n",
    "\n",
    "tx = df.copy()\n",
    "tx['date_key'] = tx['InvoiceDate'].dt.normalize().map(date_map)\n",
    "tx['product_key'] = tx['StockCode'].map(product_map)\n",
    "tx['customer_key'] = tx['CustomerID'].map(customer_map).fillna(0).astype(int)\n",
    "tx['geography_key'] = tx['Country'].map(geog_map)\n",
    "\n",
    "fact = tx[['date_key','product_key','customer_key','geography_key','InvoiceNo','Quantity','UnitPrice','sales_amount','sales_amount_abs','is_return']].copy()\n",
    "fact.rename(columns={'InvoiceNo':'invoice_no','Quantity':'quantity','UnitPrice':'unit_price'}, inplace=True)\n",
    "fact = fact.dropna(subset=['date_key','product_key','geography_key'])\n",
    "print('Fact rows:', len(fact))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae9180",
   "metadata": {},
   "source": [
    "## Example Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53113a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fact table\n",
    "fact.to_sql('FactSales', conn, if_exists='append', index=False)\n",
    "print('FactSales rows:', conn.execute('SELECT COUNT(*) FROM FactSales').fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68997f08",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0236799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analytics queries\n",
    "import pandas as pd\n",
    "\n",
    "q1 = '''\n",
    "SELECT d.year, d.quarter, p.category, ROUND(SUM(f.sales_amount),2) total_sales\n",
    "FROM FactSales f\n",
    "JOIN DimDate d ON f.date_key = d.date_key\n",
    "JOIN DimProduct p ON f.product_key = p.product_key\n",
    "WHERE f.is_return = 0\n",
    "GROUP BY d.year, d.quarter, p.category\n",
    "ORDER BY d.year, d.quarter, p.category;\n",
    "'''\n",
    "print('Sales by category per quarter')\n",
    "display(pd.read_sql(q1, conn))\n",
    "\n",
    "q2 = '''\n",
    "SELECT p.category,\n",
    "  SUM(CASE WHEN f.is_return=1 THEN -f.quantity ELSE 0 END) units_returned,\n",
    "  SUM(CASE WHEN f.is_return=0 THEN f.quantity ELSE 0 END) units_sold,\n",
    "  ROUND(1.0 * SUM(CASE WHEN f.is_return=1 THEN -f.quantity ELSE 0 END) / NULLIF(SUM(CASE WHEN f.is_return=0 THEN f.quantity ELSE 0 END),0),4) return_rate\n",
    "FROM FactSales f\n",
    "JOIN DimProduct p ON f.product_key = p.product_key\n",
    "GROUP BY p.category\n",
    "ORDER BY return_rate DESC;\n",
    "'''\n",
    "print('Return rate by category')\n",
    "display(pd.read_sql(q2, conn))\n",
    "\n",
    "q3 = '''\n",
    "SELECT g.country, d.year, d.quarter, ROUND(SUM(f.sales_amount),2) net_sales\n",
    "FROM FactSales f\n",
    "JOIN DimDate d ON f.date_key = d.date_key\n",
    "JOIN DimGeography g ON f.geography_key = g.geography_key\n",
    "GROUP BY g.country, d.year, d.quarter\n",
    "ORDER BY g.country, d.year, d.quarter LIMIT 20;\n",
    "'''\n",
    "print('Geography sales sample')\n",
    "display(pd.read_sql(q3, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868469e",
   "metadata": {},
   "source": [
    "# Basic data quality checks (0 issues expected ideally)\n",
    "checks = {\n",
    "  'amount_consistency': 'SELECT COUNT(*) c FROM FactSales WHERE sales_amount != quantity * unit_price',\n",
    "  'null_fks': 'SELECT COUNT(*) c FROM FactSales WHERE date_key IS NULL OR product_key IS NULL OR customer_key IS NULL OR geography_key IS NULL',\n",
    "  'return_flag': 'SELECT COUNT(*) c FROM FactSales WHERE (quantity < 0 AND is_return = 0) OR (quantity > 0 AND is_return=1)'\n",
    "}\n",
    "for name, sql in checks.items():\n",
    "    print(name, conn.execute(sql).fetchone()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
